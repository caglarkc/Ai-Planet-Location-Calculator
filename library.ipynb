{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılan cihaz: cuda\n",
      "%10 tamamlandı - Epoch [10/100], Train Loss: 0.1875, Val Loss: 0.1898\n",
      "%20 tamamlandı - Epoch [20/100], Train Loss: 0.1888, Val Loss: 0.1937\n",
      "%30 tamamlandı - Epoch [30/100], Train Loss: 0.1867, Val Loss: 0.1893\n",
      "%40 tamamlandı - Epoch [40/100], Train Loss: 0.1883, Val Loss: 0.1922\n",
      "%50 tamamlandı - Epoch [50/100], Train Loss: 0.1864, Val Loss: 0.1894\n",
      "%60 tamamlandı - Epoch [60/100], Train Loss: 0.1880, Val Loss: 0.1904\n",
      "%70 tamamlandı - Epoch [70/100], Train Loss: 0.1862, Val Loss: 0.1893\n",
      "%80 tamamlandı - Epoch [80/100], Train Loss: 0.1878, Val Loss: 0.1913\n",
      "%90 tamamlandı - Epoch [90/100], Train Loss: 0.1861, Val Loss: 0.1894\n",
      "%100 tamamlandı - Epoch [100/100], Train Loss: 0.1877, Val Loss: 0.1896\n",
      "Eğitim süresi: 198.79 saniye\n",
      "Test seti üzerinde ortalama kayıp değeri: 0.1876\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "# Cihazı ayarlayın (GPU varsa CUDA, yoksa CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Kullanılan cihaz:\", device)\n",
    "\n",
    "# Veriyi yükle\n",
    "file_path = \"C:/Users/alica/Desktop/300k_data.txt\"\n",
    "data = pd.read_csv(file_path, header=None, names=[\"M\", \"Peri\", \"Node\", \"Incl.\", \"E\", \"N\", \"A\", \"Epoch\"], sep=\"_\")\n",
    "\n",
    "# Gelecekteki pozisyonu (Future_Position) rastgele değerlerle dolduralım\n",
    "data[\"Future_Position\"] = np.random.uniform(2.0, 3.5, size=len(data))\n",
    "\n",
    "# Özellikleri (features) ve hedef değeri (target) ayır\n",
    "X = data[[\"M\", \"Peri\", \"Node\", \"Incl.\", \"E\", \"N\", \"A\", \"Epoch\"]].values\n",
    "y = data[\"Future_Position\"].values\n",
    "\n",
    "# Veriyi eğitim, doğrulama ve test setlerine bölme (%70 Eğitim, %20 Doğrulama, %10 Test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # %70 Eğitim\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.33, random_state=42)  # %20 Doğrulama, %10 Test\n",
    "\n",
    "# Veriyi ölçeklendir\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Veriyi PyTorch tensörlerine dönüştür ve GPU'ya taşı\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).view(-1, 1)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# PyTorch DataLoader ile veri kümelerini oluştur\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Modeli oluştur\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN().to(device)\n",
    "\n",
    "# Optimizasyon ve düzenlileştirme\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-5)\n",
    "\n",
    "# Eğitim döngüsü\n",
    "epochs = 100\n",
    "start_time = time.time()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Scheduler adımı\n",
    "    scheduler.step()\n",
    "\n",
    "    # Doğrulama seti üzerinde değerlendirme\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            val_loss += criterion(outputs, targets).item()\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Her %10 ilerlemede çıktı\n",
    "    if (epoch + 1) % (epochs // 10) == 0:\n",
    "        print(f\"%{(epoch + 1) / epochs * 100:.0f} tamamlandı - Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Eğitim süresi: {end_time - start_time:.2f} saniye\")\n",
    "\n",
    "# Test seti üzerinde değerlendirme\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        test_loss += criterion(outputs, targets).item()\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test seti üzerinde ortalama kayıp değeri: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julian Date (UTC): 2460639.5\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from astropy.time import Time\n",
    "\n",
    "# Tarihi datetime formatında oluştur\n",
    "date = datetime(2024, 11, 25)\n",
    "dateSecond = datetime(2024,12,1)\n",
    "\n",
    "# Julian Date hesapla\n",
    "jd1 = Time(date, scale='utc').jd\n",
    "jd2 = Time(dateSecond, scale= \"utc\").jd\n",
    "\n",
    "print(f\"Julian Date (UTC): {jd1}\")\n",
    "\n",
    "print(jd2-jd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/alica/Desktop/resultxx.txt\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Kepler denklemini çözmek için bir fonksiyon\n",
    "def solve_kepler(M, e, tol=1e-6):\n",
    "    E = M  # İlk tahmin\n",
    "    while True:\n",
    "        delta_E = (E - e * math.sin(E) - M) / (1 - e * math.cos(E))\n",
    "        E -= delta_E\n",
    "        if abs(delta_E) < tol:\n",
    "            break\n",
    "    return E\n",
    "\n",
    "def calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date, target_date):\n",
    "    # Zaman farkını hesapla (gün cinsinden)\n",
    "    delta_t = (target_date - epoch_date).days\n",
    "\n",
    "    # Ortalama Anomali (M)\n",
    "    M = math.radians(M0 + n * delta_t)  # Dereceden radyana\n",
    "\n",
    "    # Kepler Denklemi ile Eksen Anomali (E)\n",
    "    E = solve_kepler(M, e)\n",
    "\n",
    "    # Gerçek Anomali (nu)\n",
    "    nu = 2 * math.atan2(\n",
    "        math.sqrt(1 + e) * math.sin(E / 2),\n",
    "        math.sqrt(1 - e) * math.cos(E / 2)\n",
    "    )\n",
    "\n",
    "    # Heliocentric Distance (r) - AU cinsinde bırakıyoruz\n",
    "    r = a * (1 - e * math.cos(E))\n",
    "\n",
    "    # Yörünge Düzlemindeki Konum (x', y')\n",
    "    x_prime = r * math.cos(nu)\n",
    "    y_prime = r * math.sin(nu)\n",
    "\n",
    "    # Ekliptik Koordinatlar\n",
    "    Peri = math.radians(Peri)\n",
    "    Node = math.radians(Node)\n",
    "    Incl = math.radians(Incl)\n",
    "\n",
    "    x = (\n",
    "        x_prime * (math.cos(Node) * math.cos(Peri) - math.sin(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.cos(Node) * math.sin(Peri) + math.sin(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    y = (\n",
    "        x_prime * (math.sin(Node) * math.cos(Peri) + math.cos(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.sin(Node) * math.sin(Peri) - math.cos(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    z = (\n",
    "        x_prime * (math.sin(Peri) * math.sin(Incl)) +\n",
    "        y_prime * (math.cos(Peri) * math.sin(Incl))\n",
    "    )\n",
    "\n",
    "    return x, y, z, r\n",
    "\n",
    "def process_file(input_file, output_file, target_date):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        # Verileri ayrıştır (split('_') kullan)\n",
    "        data = line.strip().split('_')\n",
    "        M0 = float(data[0])\n",
    "        Peri = float(data[1])\n",
    "        Node = float(data[2])\n",
    "        Incl = float(data[3])\n",
    "        e = float(data[4])\n",
    "        n = float(data[5])\n",
    "        a = float(data[6])\n",
    "        epoch_date = datetime.strptime(data[7], '%Y%m%d')\n",
    "\n",
    "        # Epoch tarihindeki konumu hesapla\n",
    "        x_epoch, y_epoch, z_epoch, r_epoch = calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date, epoch_date)\n",
    "\n",
    "        # Hedef tarihteki konumu hesapla\n",
    "        x_target, y_target, z_target, r_target = calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date, target_date)\n",
    "\n",
    "        # Sonuçları formatla (yalnızca hedef tarihteki x, y, z değerleri)\n",
    "        result_line = f\"{x_target:.6f}_{y_target:.6f}_{z_target:.6f}\\n\"\n",
    "        results.append(result_line)\n",
    "\n",
    "    # Sonuçları yaz\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"C:/Users/alica/Desktop/200_data.txt\"\n",
    "    output_file = \"C:/Users/alica/Desktop/resultxx.txt\"\n",
    "    target_date_str = input(\"Enter target date (YYYYMMDD): \")\n",
    "    target_date = datetime.strptime(target_date_str, '%Y%m%d')\n",
    "\n",
    "    process_file(input_file, output_file, target_date)\n",
    "    print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/alica/Desktop/200_first.txt\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Kepler denklemini çözmek için bir fonksiyon\n",
    "def solve_kepler(M, e, tol=1e-6):\n",
    "    E = M  # İlk tahmin\n",
    "    while True:\n",
    "        delta_E = (E - e * math.sin(E) - M) / (1 - e * math.cos(E))\n",
    "        E -= delta_E\n",
    "        if abs(delta_E) < tol:\n",
    "            break\n",
    "    return E\n",
    "\n",
    "def calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date):\n",
    "    # Ortalama Anomali (M)\n",
    "    M = math.radians(M0)  # Epoch tarihinde M0 kullanılır, zaman farkı sıfırdır.\n",
    "\n",
    "    # Kepler Denklemi ile Eksen Anomali (E)\n",
    "    E = solve_kepler(M, e)\n",
    "\n",
    "    # Gerçek Anomali (nu)\n",
    "    nu = 2 * math.atan2(\n",
    "        math.sqrt(1 + e) * math.sin(E / 2),\n",
    "        math.sqrt(1 - e) * math.cos(E / 2)\n",
    "    )\n",
    "\n",
    "    # Heliocentric Distance (r) - AU cinsinde bırakıyoruz\n",
    "    r = a * (1 - e * math.cos(E))\n",
    "\n",
    "    # Yörünge Düzlemindeki Konum (x', y')\n",
    "    x_prime = r * math.cos(nu)\n",
    "    y_prime = r * math.sin(nu)\n",
    "\n",
    "    # Ekliptik Koordinatlar\n",
    "    Peri = math.radians(Peri)\n",
    "    Node = math.radians(Node)\n",
    "    Incl = math.radians(Incl)\n",
    "\n",
    "    x = (\n",
    "        x_prime * (math.cos(Node) * math.cos(Peri) - math.sin(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.cos(Node) * math.sin(Peri) + math.sin(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    y = (\n",
    "        x_prime * (math.sin(Node) * math.cos(Peri) + math.cos(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.sin(Node) * math.sin(Peri) - math.cos(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    z = (\n",
    "        x_prime * (math.sin(Peri) * math.sin(Incl)) +\n",
    "        y_prime * (math.cos(Peri) * math.sin(Incl))\n",
    "    )\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def process_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        # Verileri ayrıştır (split('_') kullan)\n",
    "        data = line.strip().split('_')\n",
    "        M0 = float(data[0])\n",
    "        Peri = float(data[1])\n",
    "        Node = float(data[2])\n",
    "        Incl = float(data[3])\n",
    "        e = float(data[4])\n",
    "        n = float(data[5])\n",
    "        a = float(data[6])\n",
    "        epoch_date = datetime.strptime(data[7], '%Y%m%d')\n",
    "\n",
    "        # Epoch tarihindeki konumu hesapla\n",
    "        x_epoch, y_epoch, z_epoch = calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date)\n",
    "\n",
    "        # Sonuçları formatla\n",
    "        result_line = f\"{line.strip()}_{x_epoch:.6f}_{y_epoch:.6f}_{z_epoch:.6f}\\n\"\n",
    "        results.append(result_line)\n",
    "\n",
    "    # Sonuçları yaz\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"C:/Users/alica/Desktop/200_data.txt\"\n",
    "    output_file = \"C:/Users/alica/Desktop/200_first.txt\"\n",
    "\n",
    "    process_file(input_file, output_file)\n",
    "    print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to C:/Users/alica/Desktop/200_data_second.txt\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from datetime import datetime\n",
    "\n",
    "# Kepler denklemini çözmek için bir fonksiyon\n",
    "def solve_kepler(M, e, tol=1e-6):\n",
    "    E = M  # İlk tahmin\n",
    "    while True:\n",
    "        delta_E = (E - e * math.sin(E) - M) / (1 - e * math.cos(E))\n",
    "        E -= delta_E\n",
    "        if abs(delta_E) < tol:\n",
    "            break\n",
    "    return E\n",
    "\n",
    "def calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date, target_date):\n",
    "    # Zaman farkını hesapla (gün cinsinden)\n",
    "    delta_t = (target_date - epoch_date).days\n",
    "\n",
    "    # Ortalama Anomali (M)\n",
    "    M = math.radians(M0 + n * delta_t)  # Dereceden radyana\n",
    "\n",
    "    # Kepler Denklemi ile Eksen Anomali (E)\n",
    "    E = solve_kepler(M, e)\n",
    "\n",
    "    # Gerçek Anomali (nu)\n",
    "    nu = 2 * math.atan2(\n",
    "        math.sqrt(1 + e) * math.sin(E / 2),\n",
    "        math.sqrt(1 - e) * math.cos(E / 2)\n",
    "    )\n",
    "\n",
    "    # Heliocentric Distance (r) - AU cinsinde bırakıyoruz\n",
    "    r = a * (1 - e * math.cos(E))\n",
    "\n",
    "    # Yörünge Düzlemindeki Konum (x', y')\n",
    "    x_prime = r * math.cos(nu)\n",
    "    y_prime = r * math.sin(nu)\n",
    "\n",
    "    # Ekliptik Koordinatlar\n",
    "    Peri = math.radians(Peri)\n",
    "    Node = math.radians(Node)\n",
    "    Incl = math.radians(Incl)\n",
    "\n",
    "    x = (\n",
    "        x_prime * (math.cos(Node) * math.cos(Peri) - math.sin(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.cos(Node) * math.sin(Peri) + math.sin(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    y = (\n",
    "        x_prime * (math.sin(Node) * math.cos(Peri) + math.cos(Node) * math.sin(Peri) * math.cos(Incl)) -\n",
    "        y_prime * (math.sin(Node) * math.sin(Peri) - math.cos(Node) * math.cos(Peri) * math.cos(Incl))\n",
    "    )\n",
    "    z = (\n",
    "        x_prime * (math.sin(Peri) * math.sin(Incl)) +\n",
    "        y_prime * (math.cos(Peri) * math.sin(Incl))\n",
    "    )\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def process_file(input_file, output_file, target_date):\n",
    "    with open(input_file, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    results = []\n",
    "    for line in lines:\n",
    "        # Verileri ayrıştır (split('_') kullan)\n",
    "        data = line.strip().split('_')\n",
    "        M0 = float(data[0])\n",
    "        Peri = float(data[1])\n",
    "        Node = float(data[2])\n",
    "        Incl = float(data[3])\n",
    "        e = float(data[4])\n",
    "        n = float(data[5])\n",
    "        a = float(data[6])\n",
    "        epoch_date = datetime.strptime(data[7], '%Y%m%d')\n",
    "\n",
    "        # Hedef tarihteki konumu hesapla\n",
    "        x_target, y_target, z_target = calculate_position(M0, Peri, Node, Incl, e, n, a, epoch_date, target_date)\n",
    "\n",
    "        # Sonuçları formatla (sadece x, y, z)\n",
    "        result_line = f\"{x_target:.6f}_{y_target:.6f}_{z_target:.6f}\\n\"\n",
    "        results.append(result_line)\n",
    "\n",
    "    # Sonuçları yaz\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.writelines(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"C:/Users/alica/Desktop/200_data.txt\"\n",
    "    output_file = \"C:/Users/alica/Desktop/200_data_second.txt\"\n",
    "    target_date_str = input(\"Enter target date (YYYYMMDD): \")\n",
    "    target_date = datetime.strptime(target_date_str, '%Y%m%d')\n",
    "\n",
    "    process_file(input_file, output_file, target_date)\n",
    "    print(f\"Results saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%70'den büyük hata payına sahip 810 satır bulundu.\n",
      "Genel Ortalama Hata Payı (filtrelenmiş): 16.7%\n",
      "Sadece ortalama yüzdelik farklarla dosya 'C:/Users/alica/Desktop/caglar.csv' olarak kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosya yolu ve çıktı dosyası\n",
    "file_path = \"C:/Users/alica/Desktop/comparison_results_fixed.csv\"  # Giriş dosyasının yolu\n",
    "output_file = \"C:/Users/alica/Desktop/caglar.csv\"  # Çıktı dosyasının adı\n",
    "\n",
    "# Verileri yükle\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Farkları hesapla ve yüzdelik farkları bul\n",
    "data['x_diff'] = ((data['x_pred'] - data['x_true']) / data['x_true']) * 100\n",
    "data['y_diff'] = ((data['y_pred'] - data['y_true']) / data['y_true']) * 100\n",
    "data['z_diff'] = ((data['z_pred'] - data['z_true']) / data['z_true']) * 100\n",
    "\n",
    "# NaN ve sonsuz değerleri temizle\n",
    "data['x_diff'] = data['x_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "data['y_diff'] = data['y_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "data['z_diff'] = data['z_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "\n",
    "# Ortalama yüzdelik fark hesaplama\n",
    "data['average_percent'] = (\n",
    "    data[['x_diff', 'y_diff', 'z_diff']].mean(axis=1)\n",
    ")\n",
    "\n",
    "# %70'ten büyük hata paylarını tespit et\n",
    "high_error_rows = data[data['average_percent'].abs() > 70]\n",
    "filtered_data = data[data['average_percent'].abs() <= 70]  # Genel hata için filtrelenmiş veriler\n",
    "\n",
    "# %70'ten büyük hata paylarının sayısını bul\n",
    "high_error_count = len(high_error_rows)\n",
    "print(f\"%70'den büyük hata payına sahip {high_error_count} satır bulundu.\")\n",
    "\n",
    "# Genel ortalama hata yüzdesini filtrelenmiş verilerle hesapla\n",
    "if len(filtered_data) > 0:\n",
    "    total_average_error = (\n",
    "        filtered_data[['x_diff', 'y_diff', 'z_diff']].abs().sum().sum() / (len(filtered_data) * 3)\n",
    "    )\n",
    "    print(f\"Genel Ortalama Hata Payı (filtrelenmiş): {total_average_error:.1f}%\")\n",
    "else:\n",
    "    print(\"Filtrelenmiş veri bulunmamaktadır, genel hata payı hesaplanamadı.\")\n",
    "\n",
    "# Ortalama yüzdelik farkları tam sayı ve bir ondalık hane olacak şekilde yuvarla\n",
    "data['average_percent'] = data['average_percent'].round(1).astype(str) + \"%\"\n",
    "\n",
    "# Sadece `average_percent` sütununu kaydet\n",
    "average_percentage = data[['average_percent']]\n",
    "average_percentage.to_csv(output_file, index=False, header=False)\n",
    "\n",
    "print(f\"Sadece ortalama yüzdelik farklarla dosya '{output_file}' olarak kaydedildi.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%70'den büyük hata payına sahip 29922 satır bulundu.\n",
      "Genel Ortalama Hata Payı (filtrelenmiş): 19.4%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dosya yolu ve çıktı dosyası\n",
    "file_path = \"C:/Users/alica/Desktop/comparison_results_fixed.csv\"  # Giriş dosyasının yolu\n",
    "# Verileri yükle\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Farkları hesapla ve yüzdelik farkları bul\n",
    "data['x_diff'] = ((data['x_pred'] - data['x_true']) / data['x_true']) * 100\n",
    "data['y_diff'] = ((data['y_pred'] - data['y_true']) / data['y_true']) * 100\n",
    "data['z_diff'] = ((data['z_pred'] - data['z_true']) / data['z_true']) * 100\n",
    "\n",
    "# NaN ve sonsuz değerleri temizle\n",
    "data['x_diff'] = data['x_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "data['y_diff'] = data['y_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "data['z_diff'] = data['z_diff'].replace([float('inf'), -float('inf')], 0).fillna(0)\n",
    "\n",
    "# Ortalama yüzdelik fark hesaplama\n",
    "data['average_percent'] = (\n",
    "    data[['x_diff', 'y_diff', 'z_diff']].mean(axis=1)\n",
    ")\n",
    "\n",
    "# %70'ten büyük hata paylarını tespit et\n",
    "high_error_rows = data[data['average_percent'].abs() > 70]\n",
    "filtered_data = data[data['average_percent'].abs() <= 70]  # Genel hata için filtrelenmiş veriler\n",
    "\n",
    "# %70'ten büyük hata paylarının sayısını bul\n",
    "high_error_count = len(high_error_rows)\n",
    "print(f\"%70'den büyük hata payına sahip {high_error_count} satır bulundu.\")\n",
    "\n",
    "# Genel ortalama hata yüzdesini filtrelenmiş verilerle hesapla\n",
    "if len(filtered_data) > 0:\n",
    "    total_average_error = (\n",
    "        filtered_data[['x_diff', 'y_diff', 'z_diff']].abs().sum().sum() / (len(filtered_data) * 3)\n",
    "    )\n",
    "    print(f\"Genel Ortalama Hata Payı (filtrelenmiş): {total_average_error:.1f}%\")\n",
    "else:\n",
    "    print(\"Filtrelenmiş veri bulunmamaktadır, genel hata payı hesaplanamadı.\")\n",
    "\n",
    "# Ortalama yüzdelik farkları tam sayı ve bir ondalık hane olacak şekilde yuvarla\n",
    "data['average_percent'] = data['average_percent'].round(1).astype(str) + \"%\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
